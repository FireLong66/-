# 数值优化概念

## 问题本质

就是从一个初始值出发，根据目标函数的局部信息作为指导根据更新规则来找到下一个解，不断迭代，一直找到使得目标函数最小（大）的自变量。其实就是给一个关于自变量x的目标函数，可能带约束，反找出满足约束且使得目标函数最优（次优）的自变量x的解。



## **核心挑战**

问题本质是很简单的，难点在于算法收敛性。

高效利用局部信息

收敛性与效率的冲突

如何处理约束与目标的冲突

全局最优性保证



## **优化过程**

数值优化的核心任务，本质上是对 “目标函数与自变量的映射关系” 进行 “逆向求解”：
已知：目标函数f(x)（输入是自变量 x，输出是衡量优劣的指标），以及可能的约束条件限制x 的取值范围）。
求解：找到一个x∗，使得在满足所有约束的前提下，f(x∗) 达到最小（或最大）—— 即 “反推” 出能让目标函数最优的自变量取值。



将优化算法视为一个**动态系统**：

- **输入**：目标函数f(x)、约束条件、初始点x_0。
- **内部机制**：
  通过局部信息生成搜索方向（如梯度方向、牛顿方向）和步长（如学习率、信赖域半径）。
- **输出**：收敛点 x^*局部最优或全局最优）。



## **优化算法的“不可能三角”**

**收敛速度**、**计算成本**、**适用范围**



## 数值优化分类

### 按约束条件分类

#### 无约束优化（Unconstrained Optimization）

- **定义**：目标函数仅依赖于变量，无任何限制条件

#### 约束优化（Constrained Optimization）

- **定义**：变量需满足一定的约束条件

### 按目标函数数量分类

#### 1. 单目标优化（Single-Objective Optimization）

- **定义**：仅需优化一个目标函数，目标明确（如最小化成本、最大化效率）。
- **特点**：最优解通常唯一（或在一个连续区域内），可通过传统方法直接求解。

#### 2. 多目标优化（Multi-Objective Optimization）

- **定义**：需同时优化多个目标函数（可能相互冲突，如成本与性能）。

- **特点**：不存在绝对最优解，而是**帕累托最优解**（无法在改进一个目标的同时不损害其他目标）。

  

### 按目标函数和约束的性质分类

根据函数的线性、凸性等性质，可分为：

#### 1. 线性优化（Linear Optimization/Linear Programming, LP）

- **定义**：目标函数和所有约束均为线性函数
- **典型方法**：单纯形法、内点法。
- **应用场景**：资源分配、生产计划等线性模型问题。

#### 2. 非线性优化（Nonlinear Optimization）

- **定义**：目标函数或约束中至少有一个是非线性函数。
- **典型方法**：牛顿法、信赖域方法、序列二次规划（SQP）。
- **应用场景**：非线性模型拟合、工程中的非线性设计优化（如曲线拟合、结构力学分析）。

#### 3. 凸优化（Convex Optimization）

- **定义**：目标函数为凸函数，可行域（约束条件构成的集合）为凸集。
- **特点**：局部最优解即为全局最优解，求解难度低，收敛性有保障。
- **典型问题**：线性规划、二次规划（正定矩阵）、凸二次约束优化等。
- **应用场景**：机器学习中的支持向量机（SVM）、最小二乘问题、信号处理等。

####  4.非凸优化（Nonconvex Optimization）

- **定义**：目标函数非凸或可行域非凸，存在多个局部最优解，全局最优解难以求解。
- 典型方法：
  - 启发式算法（遗传算法、模拟退火、粒子群优化）
  - 分支定界法（通过分割可行域寻找全局最优）
- **应用场景**：组合优化问题（如旅行商问题）、神经网络训练（非凸损失函数）等。



### 按变量类型分类

#### 1. 连续优化（Continuous Optimization）

- **定义**：变量取值为连续实数（*x*∈R*n*），是最常见的优化类型。
- **示例**：无约束优化、线性规划、非线性规划等。

#### 2. 离散优化（Discrete Optimization）

- **定义**：变量取值为离散值（如整数、二进制 0/1）。
- 子类：
  - 整数规划（变量为整数）
  - 0-1 规划（变量仅取 0 或 1，如选址问题、决策问题）
  - 组合优化（变量为离散集合中的元素，如排列、子集，如旅行商问题 TSP）
- **典型方法**：分支定界法、动态规划、启发式算法（遗传算法、蚁群算法）。
- **应用场景**：调度问题（如任务分配）、网络设计（如节点连接选择）等。

#### 3. 混合整数优化（Mixed-Integer Optimization）

- **定义**：部分变量为连续值，部分为离散值（如整数或 0/1），如混合整数线性规划（MILP）。
- **应用场景**：含离散决策的资源分配（如是否建设工厂的 0/1 变量 + 生产数量的连续变量）。



## 数值优化算法的复杂度



| **算法类型**            | **核心操作**                                                | **每次迭代时间复杂度**                    | **空间复杂度**                       | **适用场景**                           |
| ----------------------- | ----------------------------------------------------------- | ----------------------------------------- | ------------------------------------ | -------------------------------------- |
| **梯度下降法**          | 计算梯度 ∇*f*(*x**k*)                                       | *O*(*n*)                                  | *O*(*n*)                             | 大规模问题（如深度学习）               |
| **随机梯度下降（SGD）** | 随机采样计算梯度估计                                        | *O*(*b*)（*b*为 batch 大小）              | *O*(*n*)                             | 超大规模数据集（如机器学习训练）       |
| **动量梯度下降**        | 梯度 + 动量项更新                                           | *O*(*n*)                                  | *O*(*n*)                             | 加速梯度下降，减少震荡                 |
| **Nesterov 加速梯度**   | 带前瞻的梯度计算                                            | *O*(*n*)                                  | *O*(*n*)                             | 凸优化，比普通梯度下降更快             |
| **坐标下降法**          | 逐坐标优化（固定其他变量）                                  | *O*(*n*)                                  | *O*(*n*)                             | 非光滑问题（如 L1 正则化）             |
| **近端梯度法**          | 梯度 + proximal 算子（处理正则项）                          | *O*(*n*)                                  | *O*(*n*)                             | 带非光滑正则项的问题（如 L1 、L0）     |
| **共轭梯度法**          | 梯度 + 共轭方向更新                                         | *O*(*n*2)                                 | *O*(*n*)                             | 大规模线性方程组 / 二次规划            |
| **牛顿法**              | 梯度 ∇*f*(*xk*) + Hessian 矩阵 Hk + 求解 *Hkdk*=−∇*f*(*xk*) | *O*(*n*3)（主要来自矩阵求逆 / 分解）      | *O*(*n*2)（存储 Hessian 矩阵）       | 中小规模光滑问题，高精度需求           |
| **拟牛顿法（BFGS）**    | 梯度 + 近似 Hessian 矩阵（秩 1 / 秩 2 更新）                | *O*(*n*2)                                 | *O*(*n*2)（存储近似 Hessian 或其逆） | 中小规模问题，比牛顿法更稳定           |
| **L-BFGS**              | 梯度 + 有限记忆近似 Hessian                                 | *O*(*nm*)（*m*为记忆长度，通常 *m*=5∼20） | *O*(*nm*)                            | 中大规模问题（如机器学习）             |
| **信赖域方法**          | 梯度 + Hessian 矩阵 + 子问题求解                            | *O*(*n*3)（子问题含矩阵分解）             | *O*(*n*2)                            | 非凸问题，强鲁棒性                     |
| **内点法**              | 障碍函数 + 牛顿方向求解                                     | *O*(*n*3)（每步含牛顿迭代）               | *O*(*n*2)                            | 约束优化问题（如线性规划、凸二次规划） |





### 关键说明：

1. **时间复杂度核心**：
   - 一阶算法（仅用梯度）：复杂度通常为 *O*(*n*) 或 *O*(*nm*)（如 L-BFGS），适合大规模问题；
   - 二阶算法（用 Hessian 矩阵）：复杂度为 *O*(*n*3)（矩阵求逆 / 分解），适合中小规模问题，因精度高但计算成本高。
2. **空间复杂度核心**：
   - 存储梯度向量的算法（如梯度下降、SGD）：空间复杂度 *O*(*n*)；
   - 存储矩阵的算法（如牛顿法、BFGS）：空间复杂度 *O*(*n*2)，而 L-BFGS 通过有限记忆将空间降至 *O*(*nm*)（*m*≪*n*）。
3. **实际权衡**：
   - 大规模问题（如 *n*>104）：优先选择一阶算法（SGD、L-BFGS）；
   - 中小规模光滑问题（如 *n*<103）：二阶算法（牛顿法、BFGS）收敛更快，总迭代次数少，实际效率可能更高。

## 数值优化算法的收敛速度

| **法类型**                 | **收敛速度**                                                 | **适用条件**                                                 |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **梯度下降法（固定步长）** | 线性收敛（∣*x**k*+1−*x*∗∣≤*C*∣*x**k*−*x*∗∣，0<*C*<1）        | 目标函数凸且 Lipschitz 连续可微                              |
| **随机梯度下降（SGD）**    | 次线性收敛（期望意义下，E[∣*x**k*−*x*∗∣2]≤*O*(1/*k*)）       | 大规模非凸问题（如深度学习），依赖步长衰减策略               |
| **动量梯度下降**           | 线性收敛（收敛因子更小，震荡更少，实际速度快于普通梯度下降） | 凸函数，通过动量加速收敛                                     |
| **Nesterov 加速梯度**      | 线性收敛（收敛因子优于普通梯度下降，理论上达到凸优化一阶方法的最优收敛率） | 强凸函数                                                     |
| **坐标下降法**             | 线性收敛（部分场景下亚线性）                                 | 目标函数可分或凸，需满足一定光滑性（如二次函数可达到线性收敛） |
| **共轭梯度法**             | 二次收敛（针对二次函数，*n*次迭代可达最优解；非二次函数超线性收敛） | 二次函数严格收敛，非二次函数依赖 Hessian 矩阵的性质          |
| **牛顿法**                 | 二次收敛（∣*x**k*+1−*x*∗∣≤*C*∣*x**k*−*x*∗∣2）                | 目标函数二阶连续可微，Hessian 矩阵在最优解处正定，初始点足够接近*x*∗ |
| **拟牛顿法（BFGS）**       | 超线性收敛（lim*k*→∞∣*x**k*+1−*x*∗∣/∣*x**k*−*x*∗∣=0）        | 目标函数凸且光滑，Hessian 矩阵正定且 Lipschitz 连续          |
| **L-BFGS**                 | 超线性收敛（与 BFGS 类似，但依赖记忆长度*m*，*m*足够大时接近 BFGS） | 大规模问题，保持 BFGS 的收敛速度同时降低复杂度               |
| **信赖域方法**             | 二次收敛（若采用牛顿型子问题求解）                           | 非凸函数，鲁棒性强，无需初始点接近最优解                     |
| **近端梯度法**             | 线性收敛（针对凸函数，带非光滑正则项时仍保持线性收敛）       | 目标函数为光滑函数 + 非光滑正则项（如 L1 正则化）            |

### 关键说明

1. **收敛速度的 “阶”**：
   - 二次收敛 > 超线性收敛 > 线性收敛 > 次线性收敛（速度从快到慢）。
   - 二次收敛意味着 “误差每次迭代平方级减小”，例如误差从10−2到10−4仅需 1 次迭代；线性收敛则需要约log(10−2/10−4)/log(1/*C*)次迭代（依赖*C*）。
2. **条件依赖性**：
   - 收敛速度通常依赖目标函数的性质（如凸性、光滑性、Hessian 矩阵条件数）和算法参数（如步长、记忆长度）。例如，牛顿法的二次收敛仅在 “初始点足够接近最优解且 Hessian 正定” 时成立，否则可能不收敛。
3. **实际选择**：
   - 大规模问题（*n*≫104）：优先低复杂度算法（如 SGD、L-BFGS），容忍较慢的收敛速度；
   - 中小规模问题（*n*<103）：优先高收敛速度算法（如牛顿法、BFGS），即使单次迭代复杂度高，总效率仍更优。



## 算法复杂度和收敛速度关系

二者并无直接的 “正相关” 或 “负相关” 关系，而是需要根据问题场景权衡的指标。

1. **定义差异**
   - **算法复杂度**：衡量每次迭代的计算成本（如矩阵运算、梯度计算）和存储需求，核心是 “单次迭代的效率”（如 *O*(*n*) 或 *O*(*n*3)）。
   - **收敛速度**：衡量迭代序列 {*x**k*} 逼近最优解 *x*∗ 的速度，通常用收敛阶（如线性、超线性、二次）描述，核心是 “达到目标精度所需的迭代次数”。
2. **关联与权衡**
   - 高复杂度算法（如牛顿法，*O*(*n*3) 每次迭代）可能收敛速度极快（二次收敛），总计算量反而更小（适合中小规模问题）；
   - 低复杂度算法（如梯度下降，*O*(*n*) 每次迭代）可能收敛速度慢（线性收敛），但适合大规模问题（总迭代次数虽多，但单次成本极低）。
   - 例外：部分低复杂度算法（如 L-BFGS）通过近似二阶信息，可在保持低复杂度的同时提升收敛速度（超线性收敛）



# 凸优化理论

## 问题

### **凸函数乘积仍为凸函数的充要条件**

凸集乘（直和）凸集还是凸集，但凸函数乘凸函数不一定是凸函数。

设  f  和  g  为凸函数，定义  h(x) = f(x) g(x) 。则  h  是凸函数的**充要条件**为

1. **非负性**： f(x)>=0  和  g(x)>= 0  对所有  x∈{dom}(f) ∩{dom}(g)  成立。
2. **导数单调性**： f  和  g  的导数（梯度）同号，即满足以下之一：
   - 两者均单调递增（ f'(x)>=  0 ,  g'(x)>= 0 ），
   - 或两者均单调递减（ f'(x)<= 0 ,  g'(x)<=  0 ）。

#### **等价条件（二阶可导时）**

若  f  和  g  二阶可导，则  h  为凸函数的充要条件为：
$$
f''(x)g(x) + 2f'(x)g'(x) + f(x)g''(x) \geq 0 \quad \forall x.
$$
在非负性（ f, g>= 0 ）和同单调性下，该不等式自动成立。



### **封闭多边形为凸集的充要条件**

**多边形所有内角均≤180°，且任意一边所在直线的同侧包含整个多边形**。



### 凸包的交集是凸集?

**是的，凸包的交集仍然是凸集。**

**原因**：

1. **凸集的交集保持凸性**（这是凸集的基本性质）。
2. **凸包本身是凸集**，因此它们的交集也是凸集。
3. 

### 凸优化问题的局部最优解就是全局最优解吗

### 凸函数可能有多个极小值点吗？

在凸优化问题中，局部最优解一定是全局最优解。

- 凸函数若存在多个极小值点，这些点的函数值必然相等（否则违反凸函数的定义），几何上表现为函数图像在该区域 “平坦”（梯度为 0 或不存在，但函数值不变）。
- 因此，无论有多少个极小值点，它们对应的函数值都是同一个最小值，即 “极小值 = 最小值”。
- 结合凸优化问题的可行域是凸集，这些极小值点的集合也构成凸集，但整个问题的最小值（函数值）是唯一的，且所有局部最优解都是全局最优解。





## 凸集（Convex Set）

### **定义**

设集合 C⊆R*n*，若对任意 *x*,*y*∈C 和任意 *λ*∈[0,1]，都有
λx+(1−*λ*)y∈C
则称 C 为凸集。
几何意义：集合中任意两点的连线（线段）完全包含在集合内。

### **性质**

凸集的交集、仿射变换（如平移、缩放）、线性组合等仍为凸集.

分离定理: 设  C  和  D  是两个不相交的凸集（即  C ∩ D = ∅ ），则存在一个超平面  \{ x|a^T x = b \}  使得：
$$
a^T x \leq b \quad \forall x \in C, \quad \text{且} \quad a^T x \geq b \quad \forall x \in D.
$$
换句话说，存在一个超平面将  C  和  D  分离。



### 运算

1. **平移和缩放：**
   - 如果 C 是凸集，则 a C + b = \{ a x + b|x∈C \} 也是凸集。
2. **直和（Direct Sum）：**
   - 如果 C_1 和 C_2 是凸集，则 C_1 X C_2 也是凸集。
3. **凸集的加法和线性变换：**
   - 如果 C_1 和 C_2 是凸集，则 C_1 + C_2 = \{ x + y | x ∈ C_1, y ∈ C_2 \} 是凸集。
   - 如果 A 是线性变换，则 A(C) 是凸集。

## 凸函数

### 1. 凸函数（Convex Function）

#### 定义

设函数 *f*:C→R，定义域 C⊆R*n* 为凸集。若对任意 *x*,*y*∈C 和 *λ*∈[0,1]，都有
*f*(*λx*+(1−*λ*)*y*)≤*λf*(*x*)+(1−*λ*)*f*(*y*)
则称 *f* 为凸函数。

等价条件

- **一阶条件**：对任意 *x*,*y*∈D，有
  *f*(*y*)≥*f*(*x*)+∇*f*(*x*)*T*(*y*−*x*)
  几何意义：函数图像上任意一点的切线（超平面）都在函数图像下方。
- **二阶条件**（若二阶可微）：对任意 *x*∈D， Hessian 矩阵 ∇2*f*(*x*) 半正定（即 ∇2*f*(*x*)⪰0）。

### 2. 严格凸函数

对于定义域内任意两点 *x*\\=*y* 和 0<*λ*<1，满足：*f*(*λ**x*+(1−*λ*)*y*)<*λ**f*(*x*)+(1−*λ*)*f*(*y*)
几何意义：函数图像严格位于任意两点连线的下方（无重合部分）。



### 3. 强凸函数（Strongly Convex Function）

- **一阶条件**：存在常数 *m*>0，对任意 *x*,*y*∈D，有
  *f*(*y*)≥*f*(*x*)+∇*f*(*x*)*T*(*y*−*x*)+2*m*​∥*y*−*x*∥2
  几何意义：在凸函数的基础上，额外要求函数图像在切线（超平面）上方 “至少弯曲 *m*/2 的程度”，即函数有一个 “下界曲率”。
- **二阶条件**（若二阶可微）：存在常数 *m*>0，对任意 *x*∈D， Hessian 矩阵 ∇2*f*(*x*) 正定且满足 ∇2*f*(*x*)⪰*m**I*（*I* 为单位矩阵），即最小特征值不小于 *m*。





**凸函数、严格凸函数、强凸函数，的要求依次增强**

凸函数 ：函数图像无“凹陷”，但允许存在平坦区域。**极小值不唯一，但相等**

严格凸函数：函数严格“上凸”，无平坦区域（除可能的一个极小点外）。**唯一全局极小点**。

强凸函数：函数具有均匀的曲率下界，无任何平坦部分。**唯一全局极小点，且优化算法收敛更快**。

| **性质**         | **凸函数**         | **严格凸函数**     | **强凸函数**            |
| :--------------- | :----------------- | :----------------- | :---------------------- |
| **Hessian 条件** | 半正定             | 半正定，且零点唯一 | 正定（$\succeq \mu I$） |
| **平坦区域**     | 允许（如线性部分） | 仅允许在唯一极小点 | 禁止                    |
| **解的唯一性**   | 可能不唯一         | 唯一               | 唯一                    |
| **优化速度**     | 线性收敛           | 线性/超线性收敛    | 指数收敛                |



| **对比维度**             | **凸函数**                                                   | **严格凸函数**                                               | **强凸函数**                                                 |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **定义（一般形式）**     | 对定义域内任意 *x*,*y* 和 0<*λ*<1，满足： *f*(*λ**x*+(1−*λ*)*y*)≤*λ**f*(*x*)+(1−*λ*)*f*(*y*) | 对定义域内任意 *x*=*y* 和 0<*λ*<1，满足： *f*(*λ**x*+(1−*λ*)*y*)<*λ**f*(*x*)+(1−*λ*)*f*(*y*) | 存在 *m*>0，对定义域内任意 *x*,*y* 和 0<*λ*<1，满足： *f*(*λ**x*+(1−*λ*)*y*)≤*λ**f*(*x*)+(1−*λ*)*f*(*y*)−2*m**λ*(1−*λ*)∥*x*−*y*∥2 |
| **几何意义**             | 函数图像在任意两点连线的下方或重合（允许 “平坦区域”）。      | 函数图像严格在任意两点连线的下方（无重合部分，排除平坦区域）。 | 函数图像不仅严格在连线下方，且与连线的差距至少为 “二次函数级”（由 *m* 控制弯曲程度）。 |
| **一阶条件（可微时）**   | 对任意 *x*,*y*，*f*(*y*)≥*f*(*x*)+∇*f*(*x*)*T*(*y*−*x*)      | 对任意 *x*=*y*，*f*(*y*)>*f*(*x*)+∇*f*(*x*)*T*(*y*−*x*)     | 对任意 *x*,*y*，*f*(*y*)≥*f*(*x*)+∇*f*(*x*)*T*(*y*−*x*)+m/2∥y−*x*∥2 |
| **二阶可微时的等价条件** | 定义域内处处 ∇2*f*(*x*)⪰0（Hessian 半正定）                  | 定义域内处处 ∇2*f*(*x*)≻0（Hessian 正定）                    | 存在 *m*>0，定义域内处处 ∇2*f*(*x*)⪰*m**I*（Hessian 有正下界） |
| **极小值点性质**         | 极小值点构成凸集，函数值相等（可能有多个）                   | 极小值点唯一（若存在）                                       | 极小值点唯一（若存在），且有 “二次下界” 保证曲率             |
| **对优化算法的影响**     | 局部最优解即全局最优解，但可能收敛慢                         | 全局最优解唯一，收敛性优于凸函数但仍可能较慢                 | 全局最优解唯一，且优化算法（如梯度下降）具有更快的收敛速度（通常线性收敛） |
| **包含关系**             | 是最宽泛的概念，包含严格凸和强凸函数                         | 是凸函数的子集，包含强凸函数                                 | 是严格凸函数的子集，约束最强                                 |







## 凸优化问题

### 定义

在凸集上最小化凸函数的问题，标准形式为：

minf*(*x*)*，s.t. gi(x)≤0(i=1,…,m)，hj(x*)=0(*j*=1,…,*p*)
其中：

- 目标函数 *f*(*x*) 是凸函数；
- 不等式约束 gi(x) 是凸函数（因此约束集 {*x*∣*g**i*(*x*)≤0} 是凸集）；
- 等式约束 hj(x) 是仿射函数（即线性函数加常数，因此约束集 {*x*∣hj(x)=0} 是凸集）；
- 可行域（所有约束的交集）是凸集。



### 性质

**局部最优解即全局最优解**：若 *x*∗ 是凸优化问题的局部最优解（即存在邻域 *U*，对所有 *x*∈*U*∩可行域 有 *f*(*x*)≥*f*(*x*∗)），则 *x*∗ 一定是全局最优解。这是凸优化最核心的优势，避免了陷入局部最优的问题。

**最优解集合的凸性**：凸优化问题的所有最优解构成的集合是凸集（若存在多个最优解，它们的凸组合仍是最优解）。强凸函数的最优解唯一。

**无约束问题的最优性条件**对无约束凸优化问题（无 *g**i*​,*h**j*​），一阶必要条件同时也是充分条件：若 *f* 可微，*x*∗ 是最优解当且仅当 ∇*f*(*x*∗)=0（梯度为零）。



# 无约束优化

基于目标函数的一阶导数（梯度）寻找最优解，通过沿梯度负方向迭代更新变量，逐步逼近最小值。

## 线搜索法（一维搜索）

### 原理

​	在优化过程的每一步，先确定搜索方向（由梯度、牛顿方向等方法给出），再沿该方向寻找使目标函数值下降最多的步长。 

线搜索的本质是将多维优化转化为一维问题：固定方向 dk，寻找最优步长 *α*≥0。

### **精确线搜索（Exact Line Search）**

**准则**：在搜索方向上找到使目标函数值最小的步长，即：

*α*∗=arg*α*>0 min*f*(xk+αdk)



### 非精确线搜索（Inexact Line Search）

通过满足一定条件来近似选择步长，平衡计算效率和收敛性。

必要但不充分：f(xk+1)>f(xk),可能选择的xk序列，能保证f(xk)下降收敛，但不一定收敛到极小值。xk序列的选择也有影响。

#### 核心准则

为保证目标函数单调下降且迭代收敛，步长 *α* 需满足以下条件

1. Armijo 准则（充分下降条件）确保 “足够下降”，拒绝无效步长
   核心思想：确保步长能使目标函数 “足够下降”，避免步长过大导致函数值下降不足。限制步长的上界。

  直观理解：想象沿某方向下山，Armijo 准则要求 “每一步至少要向下走够一定距离”（比如线性近似能走 10 米，实际至少走 1 米），防止迈太大步反而往上滑，或方向错误根本没下山。

2. Goldstein 准则：双向限制步长，避免过短或过长

​	核心思想：在 Armijo 准则的基础上增加 “下限约束”，既防止步长过大（函数值下降不足），也防止步长过小（函数值下降过多，反而可能错过更优区域），将步长限制在一个合理的区间内。

​	直观理解：仍以下山为例，Goldstein 准则不仅要求 “至少走 1 米”（Armijo 的上限），还要求 “最多走 9 米”（下限，假设线性近似能走 10 米），避免步子太小（0.1 米）或太大（11 米），确保步长在 “1-9 米” 的合理范围。

3. Wolfe 准则：用曲率条件限制步长，兼顾下降速度

​	核心思想：不直接限制函数值的下降幅度，而是通过 “梯度变化”（曲率条件）判断步长是否合理 —— 既保证函数值足够下降（Armijo 准则），又避免步长停留在梯度下降过快的区域（防止步长过小）。

​	直观理解：下山时，除了 “至少走 1 米”（Armijo），还要求 “每一步后的陡峭程度（梯度）不能比原来陡太多”（比如原来的陡峭度是 - 10（负号表示下降），新的陡峭度至少是 - 9，即下降速度不能比原来快太多）。这避免了步长过小导致 “一直在陡坡上小步挪”，提高迭代效率。

​	**曲率条件要求新点的斜率（梯度沿搜索方向的分量）“不能比原来的斜率更陡太多”，即斜率的绝对值不能增大得太夸张，最好是往平缓的方向变化（绝对值减小），以此避免步长过小导致迭代卡在 “陡坡区域”**。避免步长过小拖慢速度

​	**别在陡坡上迈小碎步，要么迈大一点到平缓区，要么即使还在稍陡的地方，也得保证没陡得太离谱**。

​	优势：比 Goldstein 准则更灵活，能保留更多潜在优质步长，广泛应用于共轭梯度法、拟牛顿法等高效算法中。



| 准则      | 核心约束对象          | 解决的问题             | 典型应用场景             |
| --------- | --------------------- | ---------------------- | ------------------------ |
| Armijo    | 函数值下降的下限      | 避免步长过大或方向错误 | 简单梯度下降法           |
| Goldstein | 函数值下降的上下限    | 避免步长过大或过小     | 对步长范围要求严格的场景 |
| Wolfe     | 函数值下降 + 梯度变化 | 平衡下降幅度与步长效率 | 共轭梯度法、拟牛顿法等   |





## Lipschitz 连续（利普希茨条件）

### 定义

使得对任意 \(x_1, x_2)，满足∥*f*(*x*1)−*f*(*x*2)∥≤*L*⋅∥*x*1−*x*2∥

则称 f 在 D 上是 **Lipschitz 连续** 的，常数 L 称为 f 的 **Lipschitz 常数**（最小的 L 称为最佳 Lipschitz 常数）

### 几何意义

**函数图像上任意两点连线的斜率绝对值不超过 L**。即函数的变化不会 “太陡峭”，确保函数行为可控,被斜率为+- L的两条直线 “夹在中间”。

 **“函数变化不会太剧烈”**，**开凸定义域**和 **函数可微** 的前提下， 多元函数，Lipschitz 连续等价于函数梯度有界。

### 性质

1. **稳定性**：若 \(f, g\) 分别以 \(L_1, L_2\) 为 Lipschitz 常数，则：
   - \(af + bg\)（\(a,b\) 为常数）的 Lipschitz 常数为 \(|a|L_1 + |b|L_2\)；
   - 复合函数 \(f(g(x))\) 的 Lipschitz 常数为 \(L_1* L_2\)（若 g 的值域在 f 的定义域内）。
2. **收缩映射**：当 \(0 \leq L < 1\) 时，称为 **Lipschitz 收缩映射**。这类函数满足 \(||f(x_1) - f(x_2) || < \|| x_1 - x_2 ||\)，即映射后两点距离缩小，是不动点定理（如 Banach 不动点定理）的核心条件。

### 应用场景

- **微分方程解的存在性**：若微分方程 \(y' = f(x,y)\) 中的 f 关于 y 满足 Lipschitz 条件，则解存在且唯一（皮卡 - 林德洛夫定理）。

- **优化算法收敛性**：在梯度下降中，若目标函数是 Lipschitz 连续的，则可证明算法的收敛速率（如线性收敛）。

- **机器学习**：损失函数的 Lipschitz 连续性可保证训练过程的稳定性，避免梯度爆炸。

  

### 与其他连续性的关系

**Lipschitz 连续 ⇒ 一致连续 ⇒ 连续**：

**可导函数的 Lipschitz 条件**：
若 f 在区间 \([a,b]\) 上可导，且导数有界（\(|f'(x)|<= L\)），则 f 是 Lipschitz 连续的（由拉格朗日中值定理可证）。

反之，Lipschitz 连续的函数不一定可导（例如 \(f(x) = |x|\) 在 \(x=0\) 不可导，但 \(L=1\) 时满足 Lipschitz 条件）。

结论：**对于可导函数来说，导数有界等价于 Lipschitz 连续**



## Zoutendijk 定理

数值优化中关于**可行方向法**收敛性的重要理论，主要针对带约束的优化问题，给出了可行方向法收敛到**Kuhn-Tucker 点**（约束优化问题的最优性条件）的必要条件。

**可行方向法**的基本思想是：从可行点 xk出发，在可行域内寻找一个使目标函数下降的方向 dk（称为**可行下降方向**），并沿该方向进行线搜索，得到下一个可行点 xk+1=xk+αkdk（*α**k>0 为步长）。



### 收敛速度结论

1. f有下界、可微、凸函数，Δf满足lipschiz连续，次线性收敛。
2. f有下界、可微、强凸函数，Δf满足lipschiz连续，线性收敛。
3. f有下界、可微、强凸函数，Δ^(2)f<=L*I，线性收敛。





---

## 收敛速度

**收敛速度**是衡量算法效率的核心指标，它描述了迭代点列 {xk} 收敛到最优解 *x*∗ 时的快慢程度。

通常通过迭代误差 ∥*xk*−*x*∗∥（或目标函数值误差 ∣*f*(*xk*)−*f*(*x*∗)∣）随迭代次数 *k* 的衰减规律来定义。

### 收敛速度的基本定义

设 {*xk*} 收敛到 *x*∗，即 lim*k*→∞∥*xk*−*x*∗∥=0，记误差ek=∥*xk*−*x*∗∥。常见的收敛速度定义如下：

#### 1. 线性收敛（Linear Convergence）

若存在常数 0<*α*<1 和 *k*0≥0，使得对所有 *k*≥*k*0，有：
*ek*+1​≤*α*⋅*ek*​
则称 {*xk*​} **线性收敛**，*α* 称为收敛因子（*α* 越小，收敛越快）。

- 特点：误差以固定比例衰减（如每次迭代误差缩小为原来的 *α* 倍）。
- 示例：梯度下降法（在凸函数且 Lipschitz 连续条件下）、 proximal 梯度法。

#### 2. 超线性收敛（Superlinear Convergence）

若满足：
lim*k*→∞​*e**k*​*e**k*+1​​=0
则称 {*xk*​} **超线性收敛**。

- 特点：误差衰减速度快于线性收敛（比例因子随迭代趋于 0）。
- 示例：牛顿法（在最优解附近二阶导数非奇异时）、拟牛顿法（如 BFGS 算法）。

#### 3. 二次收敛（Quadratic Convergence）

若存在常数 *C*>0 和 *k*0≥0，使得对所有 *k*≥*k*0，有：
*e**k*+1​≤*C*⋅*e**k*2​
则称 {*xk*​} **二次收敛**。

- 特点：误差衰减速度远快于超线性，呈平方级衰减（如误差从 10−2 到 10−4 仅需 1 步）。
- 示例：牛顿法（在严格凸函数且二阶导数连续有界时，接近最优解阶段）。

#### 4. 亚/次线性收敛（Sublinear Convergence）

若收敛但不满足线性收敛（即 lim*k*→∞*e**k**e**k*+1=1），则称为**亚线性收敛**。

- 特点：误差衰减缓慢，可能随迭代次数呈多项式级（如 1/*k*）下降。
- 示例：最速下降法（在非二次函数上）、部分梯度下降法（步长选择不当）。



| 收敛类型        | 误差衰减规律（近似） | 迭代 10 次后的误差 | 核心特点           |
| --------------- | -------------------- | ------------------ | ------------------ |
| 亚线性          | *ek*≈1/*k*           | 10−1               | 最慢，适合简单问题 |
| 线性（*α*=0.5） | *ek*≈(0.5)*k*        | 10−3               | 稳定，应用广泛     |
| 超线性          | *ek*≈1/*k*!          | 10−7               | 快速，依赖算法设计 |
| 二次            | *ek*≈(*e*0)^(2^k)    | 10−30              | 极快，需严格条件   |

---

## 梯度下降法

基于目标函数的一阶导数（梯度）寻找最优解，通过沿梯度负方向迭代更新变量，逐步逼近最小值。

迭代公式为：x(k+1)=x(k)−η(k)⋅∇*f*(xk)

### 精确步长

若f可微，∇f是lipschitz连续，则f有二次上界:任意x,y,f(y)<=f(x)+∇f^T*(y-x)+L/2*||y-x||^2 



### 常见变种

#### 1. 批量梯度下降（Batch Gradient Descent, BGD）

- **梯度计算**：使用全部训练数据计算梯度 。
- **特点**：梯度估计准确，收敛稳定（线性收敛），但计算成本高（*O*(*N**n*) 每次迭代，*N* 为样本数，*n* 为参数维度），不适合大规模数据（如 *N*>106）。

#### 2. 随机梯度下降（Stochastic Gradient Descent, SGD）

- **梯度计算**：每次随机选取一个样本 *i*，用单个样本的梯度近似整体梯度。
- **特点**：计算成本极低（*O*(*n*) 每次迭代），适合大规模数据；但梯度估计噪声大，迭代路径震荡，收敛速度为**次线性**（期望意义下）。
- **改进**：通过 “小批量（Mini-Batch）梯度下降” 平衡效率与稳定性（每次用 *m* 个样本，1<*m*≪*N*，常见 *m*=32,64,128）。

#### 3. 动量梯度下降（Momentum Gradient Descent）

- **改进思路**：模拟物理中的 “动量”，积累历史梯度的方向，减少震荡，加速收敛。
- **迭代公式**：
  v(k+1)=γv(k)+*η*∇*f*(x(k))
  x(k+1)=x(k)−v(k+1)
  其中 *γ*∈[0,1) 为动量因子（通常取 0.9），v(k) 是积累的 “速度”。
- **特点**：在沟壑状目标函数（如深度学习中的损失函数）中，能更快穿越平坦区域，收敛速度优于普通梯度下降（仍为线性收敛，但收敛因子更小）。

#### 4. Nesterov 加速梯度（Nesterov Accelerated Gradient, NAG）

- **改进思路**：在动量法基础上，先根据历史动量 “预判” 下一步位置，再计算该位置的梯度，减少过冲。

- **迭代公式**： 
  ~x(k)=x(k)−γvk（预判位置）

  v(k+1)=γv(k)+*η*∇*f*(~x(k))
  x(k+1)=x(k)−v(k+1)

- **特点**：比普通动量法收敛更稳定，理论上达到**凸优化中一阶方法的最优收敛率**（线性收敛），广泛用于深度学习框架（如 TensorFlow、PyTorch）。



  

## 牛顿法（二阶方法）

**牛顿法的核心思想就是在当前点xk出求出二阶梯度信息，然后用二次函数进行近似拟合该函数，然后求出极小值点作为下一个点**

利用目标函数的二阶导数（Hessian 矩阵）提供曲率信息，收敛速度快于一阶方法，但计算复杂度高。

二次连续可微的目标函数*f*(*x*)，其中*x*∈R*n* ，在点*xk*处进行二阶泰勒展开：

*f*(*x*)≈*f*(x(k))+∇*f*(x(k))*T*(*x*−x(k))+1/2(*x*−x(k))*T*∇2*f*(x(k))(x−x(k))

### 核心思路

通过在当前点*xk*处用上述二阶泰勒展开式近似目标函数*f*(*x*)，然后求解这个近似二次函数的极小值点，将其作为下一次迭代的点x(k+1)。

近似的二次函数*q*(*x*)=*f*(xk)+∇*f*(*xk*)*T*(*x*−*xk*)+21(*x*−xk)T∇2*f*(xk)(*x*−xk)

对*q*(*x*)求关于*x*的梯度，并令其等于 0：

∇*q*(*x*)=∇*f*(*xk*)+∇2*f*(*xk*)(*x*−*xk*)=0

解上述方程，得到：

*x*=*xk*−[∇2*f*(*xk*)]−1∇*f*(*xk*)

我们就将*x*作为下一次迭代的点*x**k*+1，即迭代公式为：

*x*(k+1)=*xk*−[∇2*f*(*xk*)]−1∇*f*(*xk*) 需要计算hessian矩阵的逆



## 回退法

### 核心思想

在迭代优化中，当按当前搜索方向和步长可能导致目标函数值上升时，通过**逐步缩小步长**（回退），找到一个使目标函数值下降的可接受步长，确保迭代过程的有效性。

**在保证充分下降的前提下，自适应地寻找合适的步长**。通过逐步回退（缩小）步长，在下降速度和函数值改善之间取得平衡。

### 本质原理

基于**Armijo 准则**（或类似的下降条件）：
对于当前迭代点 *x**k*​、搜索方向 *d**k*​，需找到步长 *α* 满足：*f*(*xk*​+*α**d**k*​)≤*f*(*xk*​)+*cα*∇*f*(*xk*​)*T**d**k*​
其中 0<*c*<1 为常数。
本质是**在保证目标函数下降的前提下，避免步长过大导致迭代失效，同时不过度缩小步长以保证效率**。

### 过程步骤

1. **初始化**：给定初始步长 *α*0（通常较大，如 1）、收缩因子 *ρ*（0<*ρ*<1，如 0.5）、常数 *c*。
2. **检验条件**：计算 *f*(*xk*+*α*0*dk*)，判断是否满足 Armijo 准则。
3. **回退调整**：若不满足，令 *α*=*ρ**α*，重复步骤 2。
4. **确定步长**：当找到满足条件的 *α* 时，以该步长更新迭代点：*x**k*+1=*x**k*+*α**d**k*。

---

## **拟牛顿法**

​	为解决牛顿法中计算和存储 Hessian 矩阵及其逆矩阵成本过高、且可能出现非正定问题而提出的一类数值优化算法。只需要有hessian的逆矩阵的近似值就可以了

​	**用梯度变化 “间接学习” 函数的局部曲率**，在计算成本与收敛速度之间取得平衡，是数值优化中最常用的方法之一。

​	其核心思想是**不直接计算 Hessian 矩阵，而是通过迭代过程中收集的梯度信息，逐步 “近似” Hessian 矩阵或其逆矩阵**，同时保留牛顿法利用二阶信息加速收敛的优势。

- 梯度差：**y**k*=∇*f*(*x**k*+1)−∇*f*(*x**k)（相邻两点的梯度变化）
- 步长差：**s**k*=*x**k*+1−*x**k（相邻两点的位置变化）

BFGS 算法（最常用的拟牛顿法）

---



# 约束优化



## 增广拉格朗日法

#### 核心思想

通过在拉格朗日函数中引入**惩罚项**（通常为约束违反量的平方项），将约束优化问题转化为一系列无约束优化子问题，同时保留拉格朗日乘子对约束的调节作用，平衡约束满足与目标优化。

#### 本质原理

1. **融合拉格朗日乘子与惩罚机制**：既利用乘子引导搜索方向（类似拉格朗日法），又通过惩罚项强制约束满足（类似惩罚函数法），避免惩罚函数法中惩罚系数过大导致的数值病态。
2. **迭代改进**：通过交替更新目标函数的近似形式（增广拉格朗日函数）、求解无约束子问题、更新拉格朗日乘子，逐步逼近原约束问题的最优解。

#### 过程步骤（以不等式约束问题为例，目标函数 min*f*(*x*)，约束 *g**i*(*x*)≤0）

1. **初始化**：设定初始点 *x*0、拉格朗日乘子 *λ*0≥0、惩罚系数 *μ*0>0，迭代次数 *k*=0。
2. **构造增广拉格朗日函数**：Lμ(*x*,*λ*)=*f*(*x*)+∑*i*=1,m λigi(x)+μ/2∑i=1,m max(*gi*(*x*),−λi/μ)^2
3. **求解无约束子问题**：找到 *xk*+1 使 *L**μ**k*(*x*,*λk*) 最小。
4. **更新拉格朗日乘子**：*λi*,*k*+1=max(0,*λi*,*k*+*μ**k**gi*(*xk*+1))
5. **调整惩罚系数**：通常保持 *μk* 不变或适度增大（如 μk+1=βμk，*β*>1）。
6. **收敛判断**：若约束违反量和目标函数变化量小于阈值，停止迭代；否则，*k*=*k*+1，返回步骤 2。



## 精确罚函数

#### 核心思想

通过构造含**绝对值或最大值项**的罚函数，在**有限惩罚系数**下，使罚函数的无约束最优解**等价于原约束问题的最优解**，无需惩罚系数趋于无穷大。

#### 本质原理

1. **直接量化约束违反成本**：用罚函数项（如 ∑∣max(*g**i*(*x*),0)∣）精确反映约束违反程度，而非惩罚函数法的平方项。
2. **有限系数下的等价性**：当惩罚系数超过某一阈值（与问题最优拉格朗日乘子相关）时，罚函数的无约束最优解恰好满足原约束条件，且与原问题最优解一致。

#### 过程步骤（以不等式约束问题 min*f*(*x*)，*g**i*(*x*)≤0 为例）

1. **构造精确罚函数**：*P*(*x*,*σ*)=*f*(*x*)+*σ*∑*i*=1*m*max(*g**i*(*x*),0)
   其中 *σ*>0 为惩罚系数，max(*g**i*​(*x*),0) 表示约束违反量。
2. **确定阈值**：选择 *σ* 大于原问题最优拉格朗日乘子的上界（实际中可通过试算调整）。
3. **求解无约束问题**：找到 *x*∗ 使 *P*(*x*,*σ*) 最小。
4. **验证等价性**：若 *σ* 足够大，*x*∗ 必满足所有约束，且为原约束问题的最优解。
5. **收敛判断**：若 *x*∗ 满足约束且罚函数梯度为零，停止迭代。



## 二次罚函数

#### 核心思想

通过在目标函数中引入**约束违反量的平方项**作为惩罚，将约束优化问题转化为一系列无约束优化问题，通过逐步增大惩罚系数，迫使无约束解收敛到原约束问题的最优解。

#### 本质原理

1. **惩罚机制**：对违反约束的点施加惩罚（违反越严重，惩罚越大），引导搜索向可行域靠近。
2. **极限收敛**：当惩罚系数趋于无穷大时，无约束子问题的最优解收敛到原约束问题的最优解，但系数过大会导致数值病态（如 Hessian 矩阵条件数恶化）。

#### 过程步骤（以约束问题 min*f*(*x*)，s.t. *h**j*(*x*)=0，gi(x)≤0 为例）

1. **构造二次罚函数**：*P*(*x*,*μ*)=*f*(*x*)+μ/2(∑*j*=1,p hj(*x*)^2+∑*i*=1,m[max(*gi*(*x*),0)]^2)
   其中 *μ*>0 为惩罚系数，平方项量化约束违反程度。
2. **初始化**：选择初始点 *x*0、初始惩罚系数 *μ*1>0，迭代次数 *k*=1。
3. **求解无约束子问题**：找到 *x**k* 使 *P*(*x*,*μ**k*) 最小。
4. **调整惩罚系数**：增大系数（如 *μ**k*+1=*β**μ**k*，*β*>1）。
5. **收敛判断**：若约束违反量（平方和）小于阈值，停止迭代；否则，*k*=*k*+1，返回步骤 3。最终 *x**k* 逼近原问题最优解。



