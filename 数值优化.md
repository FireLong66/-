

# 数值优化概念

## 问题本质

就是从一个初始值出发，根据目标函数的局部信息作为指导根据更新规则来找到下一个解，不断迭代，一直找到使得目标函数最小（大）的自变量。其实就是给一个关于自变量x的目标函数，可能带约束，反找出满足约束且使得目标函数最优（次优）的自变量x的解。



## **核心挑战**

问题本质是很简单的，难点在于算法收敛性。

高效利用局部信息

收敛性与效率的冲突

如何处理约束与目标的冲突

全局最优性保证



## **优化过程**

数值优化的核心任务，本质上是对 “目标函数与自变量的映射关系” 进行 “逆向求解”：
已知：目标函数f(x)（输入是自变量 x，输出是衡量优劣的指标），以及可能的约束条件限制x 的取值范围）。
求解：找到一个x∗，使得在满足所有约束的前提下，f(x∗) 达到最小（或最大）—— 即 “反推” 出能让目标函数最优的自变量取值。



将优化算法视为一个**动态系统**：

- **输入**：目标函数f(x)、约束条件、初始点x_0。
- **内部机制**：
  通过局部信息生成搜索方向（如梯度方向、牛顿方向）和步长（如学习率、信赖域半径）。
- **输出**：收敛点 x^*局部最优或全局最优）。



## **优化算法的“不可能三角”**

**收敛速度**、**计算成本**、**适用范围**



## 数值优化分类

### 按约束条件分类

#### 无约束优化（Unconstrained Optimization）

- **定义**：目标函数仅依赖于变量，无任何限制条件

#### 约束优化（Constrained Optimization）

- **定义**：变量需满足一定的约束条件

### 按目标函数数量分类

#### 1. 单目标优化（Single-Objective Optimization）

- **定义**：仅需优化一个目标函数，目标明确（如最小化成本、最大化效率）。
- **特点**：最优解通常唯一（或在一个连续区域内），可通过传统方法直接求解。

#### 2. 多目标优化（Multi-Objective Optimization）

- **定义**：需同时优化多个目标函数（可能相互冲突，如成本与性能）。

- **特点**：不存在绝对最优解，而是**帕累托最优解**（无法在改进一个目标的同时不损害其他目标）。

  

### 按目标函数和约束的性质分类

根据函数的线性、凸性等性质，可分为：

#### 1. 线性优化（Linear Optimization/Linear Programming, LP）

- **定义**：目标函数和所有约束均为线性函数
- **典型方法**：单纯形法、内点法。
- **应用场景**：资源分配、生产计划等线性模型问题。

#### 2. 非线性优化（Nonlinear Optimization）

- **定义**：目标函数或约束中至少有一个是非线性函数。
- **典型方法**：牛顿法、信赖域方法、序列二次规划（SQP）。
- **应用场景**：非线性模型拟合、工程中的非线性设计优化（如曲线拟合、结构力学分析）。

#### 3. 凸优化（Convex Optimization）

- **定义**：目标函数为凸函数，可行域（约束条件构成的集合）为凸集。
- **特点**：局部最优解即为全局最优解，求解难度低，收敛性有保障。
- **典型问题**：线性规划、二次规划（正定矩阵）、凸二次约束优化等。
- **应用场景**：机器学习中的支持向量机（SVM）、最小二乘问题、信号处理等。

####  4.非凸优化（Nonconvex Optimization）

- **定义**：目标函数非凸或可行域非凸，存在多个局部最优解，全局最优解难以求解。
- 典型方法：
  - 启发式算法（遗传算法、模拟退火、粒子群优化）
  - 分支定界法（通过分割可行域寻找全局最优）
- **应用场景**：组合优化问题（如旅行商问题）、神经网络训练（非凸损失函数）等。



### 按变量类型分类

#### 1. 连续优化（Continuous Optimization）

- **定义**：变量取值为连续实数（*x*∈R*n*），是最常见的优化类型。
- **示例**：无约束优化、线性规划、非线性规划等。

#### 2. 离散优化（Discrete Optimization）

- **定义**：变量取值为离散值（如整数、二进制 0/1）。
- 子类：
  - 整数规划（变量为整数）
  - 0-1 规划（变量仅取 0 或 1，如选址问题、决策问题）
  - 组合优化（变量为离散集合中的元素，如排列、子集，如旅行商问题 TSP）
- **典型方法**：分支定界法、动态规划、启发式算法（遗传算法、蚁群算法）。
- **应用场景**：调度问题（如任务分配）、网络设计（如节点连接选择）等。

#### 3. 混合整数优化（Mixed-Integer Optimization）

- **定义**：部分变量为连续值，部分为离散值（如整数或 0/1），如混合整数线性规划（MILP）。
- **应用场景**：含离散决策的资源分配（如是否建设工厂的 0/1 变量 + 生产数量的连续变量）。







# 无约束优化

基于目标函数的一阶导数（梯度）寻找最优解，通过沿梯度负方向迭代更新变量，逐步逼近最小值。

## 线搜索法（一维搜索）

### 原理

​	在优化过程的每一步，先确定搜索方向（由梯度、牛顿方向等方法给出），再沿该方向寻找使目标函数值下降最多的步长。 

线搜索的本质是将多维优化转化为一维问题：固定方向 dk，寻找最优步长 *α*≥0。

### **精确线搜索（Exact Line Search）**

**准则**：在搜索方向上找到使目标函数值最小的步长，即：

*α*∗=arg*α*>0 min*f*(xk+αdk)



### 非精确线搜索（Inexact Line Search）

通过满足一定条件来近似选择步长，平衡计算效率和收敛性。

必要但不充分：f(xk+1)>f(xk),可能选择的xk序列，能保证f(xk)下降收敛，但不一定收敛到极小值。xk序列的选择也有影响。

#### 核心准则

为保证目标函数单调下降且迭代收敛，步长 *α* 需满足以下条件









## 梯度下降法

基于目标函数的一阶导数（梯度）寻找最优解，通过沿梯度负方向迭代更新变量，逐步逼近最小值。

## 牛顿法及改进（二阶方法）

利用目标函数的二阶导数（Hessian 矩阵）提供曲率信息，收敛速度快于一阶方法，但计算复杂度高。
